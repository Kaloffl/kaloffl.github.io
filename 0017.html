<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="alternate" type="application/atom+xml"  title="Atom Feed" href="feed.xml">
    <link rel="stylesheet" type="text/css" href="style.css">
    <title>117-bit constants with 64-bit floats - Lars' Website</title>
  </head>

  <body>

    <header>
      <nav>
        <h1><a href="index.html">Lars' website</a></h1>
        <a href="archive.html" title="archive">Archive</a>
        <a href="feed.xml" title="feed">Feed</a>
      </nav>
    </header>

    <article> 
      <header>
        <h2>117-bit constants with 64-bit floats</h2>
        <div>First published: <time>2023-03-01</time></div>
      </header>

      <section>
        <p>
While looking for ways to implement <code>asin</code> from scratch, I came across a few answers by <a href="https://stackoverflow.com/users/780717/njuffa" target="_blank">Norbert Juffa</a> on stackoverflow.
In <a href="https://stackoverflow.com/questions/28969184/is-there-an-accurate-approximation-of-the-acos-function/42683455#42683455" target="_blank">one of them</a> we find this curiosity:
        </p>
        <code>
          <pre>
<span>/* arccos(x) = pi/2 - arcsin(x) */</span>
<span>r = fma (9.3282184640716537e-1, 1.6839188885261840e+0, asin_core (r));</span>
          </pre>
        </code>
        <p>
While the comment talks about dividing π by 2 and subtracting from it, the code looks nothing like it, so what's going on?
        </p>
        <p>
First of all, the function <code>fma</code> is a fused-multiply-add, which means that it does <code>fma(a, b, c) = (a*b)+c</code> in one step.
The reason that this deserves a special function is, that the result ob <code>a*b</code> is not rounded, but added to <code>c</code> in "infinite precision".
Rounding will only happen after the addition.
Infinite in this case means 106 bits of mantissa to hold the product of the two 53-bit mantissas.
        </p>
        <p>
Second, <code>r</code> has been negated previously, so the call to <code>asin_core</code> will return a negative number.
The comment might have been more accurate as <code>arccos(x) = pi/2 + arcsin(-x)</code>.
        </p>
        <p>
And finally those numbers.
When multiplying them together, we get <code>1.570796327...</code> which is indeed close to <code>π/2</code>.
The trick is in the fused-multiply-add: like I said, the resulting mantissa of the multiplication is not immediately rounded and stuffed back into 53 bits, which means that this temporary result can hold more bits of precision than a regular double.
So if we need a number with up to 106 bits of precision, we can factor it into two doubles and let <code>fma</code> work its magic.
        </p>
        <p>
However, we can only profit from this trick, if the result after the <code>fma</code> is smaller than the constant, otherwise there is nowhere to put those extra bits and the rounding after the <code>fma-addition</code> will delete them.
The reason it works if the result is smaller, is because the temporary result of the <code>fma-addition</code> before the rounding will have leading zeros.
The FPU will shift the result to the left until the highest bit is a 1 (unless we're in the realm of subnormal values) and stuff those bits into the double mantissa.
During this shifting, those extra bits of precision get moved in from the right.
        </p>
        <p>
Here's my attempt to show the same thing happening with decimal numbers and scientific notation.
Numbers are limited to 3 digits (except during <code>fma</code>), one before the dot and two after.
They are rounded as usual: < 0.5 down, ≥ 0.5 up.
        </p>
      </section>
      <code>
        <pre>
Example calculation π/2 - 0.0754 ≈ 1.495396327:

Naive:
1.57*10<sup>0</sup> - 7.45*10<sup>-2</sup>
≈ 1.57*10<sup>0</sup> - 0.0745*10<sup>0</sup> // after shifting to same exponent
≈ 1.4946*10<sup>0</sup>            // after subtraction
≈ 1.49*10<sup>0</sup>              // after rounding and truncation

With FMA:
(5.59*10<sup>-1</sup> * 2.81*10<sup>0</sup>) - 7.54*10<sup>-2</sup>
≈ 1.57079*10<sup>0</sup> - 7.54*10<sup>-2</sup>  // after internal multiplication
≈ 1.57079*10<sup>0</sup> - 0.0754*10<sup>0</sup> // after shifting to same exponent
≈ 1.49539*10<sup>0</sup>              // after subtraction
≈ 1.50*10<sup>0</sup>                 // after rounding and truncation

        </pre>
      </code>
      <section>
        <p>
Here we see, that the <code>FMA</code> version correctly rounds up, while die normal solution rounds down (which is correct for <code>1.57</code>, but wrong for <code>π/2</code>).
It was a bit tricky to construct this example, because in most cases you get correct rounding anyways.
        </p>
        <p>
Another tricky part is to find the two numbers that, when multiplied together, best approximate <code>π/2</code>.
For my example I simply iterated over all three-digit numbers, trying both equal exponents and slightly different ones.
That approach would take a bit longer for all 72 quadrillion values you can have with a double.
        </p>
      </section>

      <section>
        <h2>Change-log</h2>
        <ul>
          <li>2023-03-02 - Fixed the title, writing and example.</li>
          <li>2023-03-01 - Initial post.</li>
        </ul>
      </section>

    </article>

    <footer>
      <a href="changelog.html">Change-log</a>
    </footer>
  </body>
</html>